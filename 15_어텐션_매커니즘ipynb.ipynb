{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOd0kWcRZxWzDJGT2QCMCcm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HJJunn/DeepLearning---NLP/blob/main/15_%EC%96%B4%ED%85%90%EC%85%98_%EB%A7%A4%EC%BB%A4%EB%8B%88%EC%A6%98ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#양방향 LSTM과 어텐션 매커니즘"
      ],
      "metadata": {
        "id": "laajBWEG9E89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. IMDB 리뷰 데이터 전처리하기"
      ],
      "metadata": {
        "id": "HIbvIBlL9E6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fToxR9f48p3u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "(X_train, y_train),(X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5w473ek-fVy",
        "outputId": "974aed88-2dcd-48ec-9b71-86843404c804"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"리뷰 최대 길이:\", max(len(l) for l in X_train))\n",
        "print(\"리뷰 평균 길이:\", sum(map(len, X_train))/ len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exs1WJ2B-o0b",
        "outputId": "bddd5797-d261-4233-d373-9d527e2a9f07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰 최대 길이: 2494\n",
            "리뷰 평균 길이: 238.71364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "metadata": {
        "id": "tGwMy25E-6HV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT-RhnQB-8H6",
        "outputId": "f92137c8-5d76-4f0d-816d-8a4627ebbff1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 500)\n",
            "(25000, 500)\n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 바다나우 어텐션"
      ],
      "metadata": {
        "id": "dZbgTeBo_QN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class BahdanauAttention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = Dense(units)\n",
        "        self.W2 = Dense(units)\n",
        "        self.V = Dense(1)\n",
        "\n",
        "    def call(self, values, query): # key == value\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "4tuaopyV-8cV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 양방향 LSTM + 어텐션 매커니즘"
      ],
      "metadata": {
        "id": "nTQ3Y5TPBpnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout, Masking\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "metadata": {
        "id": "-j-4qyzg-8oC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape = (max_len,), dtype = 'int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length = max_len)(sequence_input)\n",
        "embedded_masking = Masking(mask_value = 0.0)(embedded_sequences)"
      ],
      "metadata": {
        "id": "hVJ8zQJIB-D1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = Bidirectional(LSTM(64, dropout = 0.5, return_sequences = True))(embedded_masking)"
      ],
      "metadata": {
        "id": "VHvXYjcpFS7C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout = 0.5, return_sequences = True, return_state = True))(lstm)"
      ],
      "metadata": {
        "id": "JLc83T7uFfgm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Bo68gqFyD6",
        "outputId": "4ba50a98-b155-42ba-f33f-0eaafd4c4941"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate(([forward_c, backward_c]))"
      ],
      "metadata": {
        "id": "-XfvWkVFHFHb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(64)\n",
        "context_vector,attention_weights = attention(lstm, state_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLozE5s6HkRl",
        "outputId": "daa0d088-35f5-4020-e204-6ae1ae405f4f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'bahdanau_attention_1' (of type BahdanauAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = Dense(20, activation = \"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation = \"sigmoid\")(dropout)\n",
        "model = Model(inputs = sequence_input, outputs = output)"
      ],
      "metadata": {
        "id": "ufl96liUHxeS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "hpjgxahcIFhy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ-AdQH_Ia_Z",
        "outputId": "c84b9047-a2c7-47b9-cbfc-2c22c1b38e6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'bahdanau_attention_1' (of type BahdanauAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1148s\u001b[0m 12s/step - accuracy: 0.5679 - loss: 0.6556 - val_accuracy: 0.8644 - val_loss: 0.3245\n",
            "Epoch 2/3\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1217s\u001b[0m 12s/step - accuracy: 0.8938 - loss: 0.2866 - val_accuracy: 0.8818 - val_loss: 0.2810\n",
            "Epoch 3/3\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1162s\u001b[0m 12s/step - accuracy: 0.9231 - loss: 0.2165 - val_accuracy: 0.8907 - val_loss: 0.2728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(X_test, y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDtGQ0eYIm3I",
        "outputId": "f306fcb8-0dff-4d71-a4d9-e76800e915db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 377ms/step - accuracy: 0.8927 - loss: 0.2705\n",
            "0.890720009803772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZytU_h_hIzZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}