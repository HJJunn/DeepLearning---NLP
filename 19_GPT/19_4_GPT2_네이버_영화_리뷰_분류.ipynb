{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FdQ8A-qndwR",
    "outputId": "a3887ce0-ad89-4bbe-f2bc-9b04c6318dff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, TFGPT2Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "id": "CFBVQlTInhhn"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) 데이터 확인"
   ],
   "metadata": {
    "id": "uEnJt4e8oz_g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6aazH4sn4SC",
    "outputId": "5b2b1597-397a-4f44-c289-c1d5f6f9dc59"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7a87d68811d0>)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')"
   ],
   "metadata": {
    "id": "a-CVvG39n7vu"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(train_data), len(test_data))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCoSPyoLoJyq",
    "outputId": "22a29ecb-80f1-469f-cff7-76b01884cf42"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "150000 50000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#중복, 결측값 제거\n",
    "train_data = train_data.drop_duplicates(subset = ['document'])\n",
    "train_data = train_data.dropna(how = 'any')\n",
    "len(train_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6MXx5TkoQai",
    "outputId": "35180713-7ef4-4e0f-9649-4e24a99e5272"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = test_data.dropna(how = 'any')\n",
    "len(test_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3oF4UL1ooIR",
    "outputId": "170f9881-094c-462c-cf97-bd63841ec6f4"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49997"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) GPT의 입력"
   ],
   "metadata": {
    "id": "ciT-pRRdo2_O"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\", bos_token = '</s>', eos_token = '</s>', pad_token = '<pad>')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "8a2c59bc367c4c56a655b2e3d920f801",
      "cf27a097f72d4468a74bc62081c9b90c",
      "0a9838f1a3e64a3a8b0e81a77967705e",
      "4185feae7f0d4d07a6032b35c565096a",
      "e88b15286ca44e70a063c3b27dd4d411",
      "d104295343e8412a821b8711dc28acf7",
      "1e45e061f7ec47a8b77f6a8003016664",
      "3959fda6057f4f5c9c4d1e3f19ba038b",
      "ef08f86058ae401aa46a3c10a0de1336",
      "0c66d357c4164440bd74be0e96b3353f",
      "f284236988174bf092fd6382c474d86e",
      "08e0b1f9dfb44b598457866ed86b511e",
      "64134fa445ef408297b7e94492cf8eaa",
      "81c4ad1761d74022a087915c7a1c474e",
      "f4d51521fd8a4348b7228612040404ff",
      "905c3949dc89452692e8b7d8b7d15501",
      "f98f9e97592a4e29824ec438d6750dee",
      "15ce91c641ab44b69696a414c4193a8d",
      "713cb65fd7fe456bbbb4740c865f2096",
      "d6efb6c0a099406585187857dabee728",
      "de86ffd1e7b645debad15e2af415d4cc",
      "68b62c6f994b4189a464339f0277cead"
     ]
    },
    "id": "zn-Kb2q_otrF",
    "outputId": "6b7463cd-b691-40ee-edb3-0c81dcf6bc71"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a2c59bc367c4c56a655b2e3d920f801"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08e0b1f9dfb44b598457866ed86b511e"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqJy9RTrpK6e",
    "outputId": "7137453a-58ac-484a-a8e0-74d6df0c0b6b"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁보는', '내', '내', '▁그대로', '▁들어', '맞', '는', '▁예측', '▁카', '리스', '마', '▁없는', '▁악', '역']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.decode(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "UYzog-4JpTkY",
    "outputId": "bc2fc7e4-45f6-40ff-b08c-16ed517bde51"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'보는내내 그대로 들어맞는 예측 카리스마 없는 악역'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tokenizer.decode(3))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJqddO3Gpd7R",
    "outputId": "59058d69-b1b1-4d89-c6ad-d1a3ac76e30d"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<pad>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_seq_len = 128\n",
    "encoded_result = tokenizer.encode(\"전율을 일으키는 영화. 다시 보고 싶은 영화\", max_length = max_seq_len, padding = 'max_length', truncation = True)\n",
    "print(encoded_result)\n",
    "print(len(encoded_result))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2cGTvGDphlm",
    "outputId": "7bea7825-4c7f-4c5b-e104-8453f9ad86d1"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9034, 13555, 16447, 10584, 389, 9427, 10056, 22386, 10584, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "128\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 전체 데이터 전처리\n",
    "def convert_features(examples,labels, max_seq_len, tokenizer):\n",
    "  input_ids, data_labels = [], []\n",
    "\n",
    "  for example, label in tqdm(zip(examples, labels), total = len(examples)):\n",
    "    eos_token = [tokenizer.eos_token]\n",
    "    bos_token = [tokenizer.bos_token]\n",
    "    tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
    "\n",
    "    input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_id = pad_sequences([input_id] , maxlen = max_seq_len, value = tokenizer.pad_token_id, padding = 'post')[0]\n",
    "\n",
    "    assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "\n",
    "    input_ids.append(input_id)\n",
    "    data_labels.append(label)\n",
    "\n",
    "  input_ids = np.array(input_ids, dtype = 'int')\n",
    "  data_labels = np.asarray(data_labels, dtype = np.int32)\n",
    "  return input_ids, data_labels"
   ],
   "metadata": {
    "id": "YLVKBedpp6Qq"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_X, train_y = convert_features(train_data['document'], train_data['label'], max_seq_len = max_seq_len, tokenizer = tokenizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFqnbOfgr-Ue",
    "outputId": "42047b4b-00db-4e94-ede1-723dba1cc1d7"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 146182/146182 [00:27<00:00, 5274.84it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_X, test_y = convert_features(test_data['document'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQagseMpsMkY",
    "outputId": "850ae216-dde9-4b73-fcba-565bfa3e7b4d"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 49997/49997 [00:07<00:00, 6306.34it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_id = train_X[0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a9H3KAjsZKV",
    "outputId": "89371206-2722-42ec-945a-cb59bb03be69"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "단어에 대한 정수 인코딩 : [    1  9050  9267  7700  9705 23971 12870  8262  7055  7098  8084 48213\n",
      "     1     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : </s> 아 더빙.. 진짜 짜증나네요 목소리</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "레이블 : 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) GPT를 이용한 텍스트 분류 모델 만들기"
   ],
   "metadata": {
    "id": "vErBBwmesyaq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = TFGPT2Model.from_pretrained(\"skt/kogpt2-base-v2\", from_pt = True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181,
     "referenced_widgets": [
      "d07d36a22e8c431f835c126a84150f0e",
      "fe2421f17eb149348c610080a5a2b358",
      "13671fce5f8e4c208b8ae83b7c0a923a",
      "57a306b2823849659afd14f9375bb241",
      "65bbbec1dfb04fab9cc7ff1ada7813ed",
      "c70cebc4bb87493aaf97ae9bf679cfe7",
      "ae91af5f383c4d988246fd9a0cc09b23",
      "0b2c50ab2a4543b198dc64d56b7e4a85",
      "69ccfd64404748e7a659b9fbe05fb137",
      "c8590bc21eb6437dbd4daba121635b60",
      "0b4f357cd8794543ac65af8eb2f08097"
     ]
    },
    "id": "a9f0QkmPsdZF",
    "outputId": "4cb67bc5-7c58-4c30-acab-126c3508c491"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d07d36a22e8c431f835c126a84150f0e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.8.attn.masked_bias', 'lm_head.weight', 'transformer.h.1.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.2.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
    "  def __init__(self, model_name):\n",
    "    super(TFGPT2ForSequenceClassification, self).__init__()\n",
    "    self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt = True)\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.classifier = tf.keras.layers.Dense(1, kernel_initializer =tf.keras.initializers.TruncatedNormal(0.02), activation = 'sigmoid', name = 'classifier')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    outputs = self.gpt(input_ids = inputs)\n",
    "    cls_token = outputs[0][:, -1]\n",
    "    cls_token = self.dropout(cls_token)\n",
    "    prediction = self.classifier(cls_token)\n",
    "\n",
    "    return prediction"
   ],
   "metadata": {
    "id": "SfBUZoEHs9yz"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH5jhXV5tSXE",
    "outputId": "483b786c-e181-4f2b-b1dd-0d8f0b6968ff"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.8.attn.masked_bias', 'lm_head.weight', 'transformer.h.1.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.2.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(train_X, train_y, epochs=2, batch_size=32, validation_split=0.2)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZksvsuatwegE",
    "outputId": "49513770-0430-41c1-86f6-c23ed798c37f"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m3655/3655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 312ms/step - accuracy: 0.4960 - loss: 0.8772 - val_accuracy: 0.5989 - val_loss: 0.6709\n",
      "Epoch 2/2\n",
      "\u001b[1m3655/3655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1156s\u001b[0m 311ms/step - accuracy: 0.6028 - loss: 0.6656 - val_accuracy: 0.6553 - val_loss: 0.6409\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a87d5a439d0>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = model.evaluate(test_X, test_y, batch_size = 1024)\n",
    "print('test loss, test acc: ', results)"
   ],
   "metadata": {
    "id": "CSR3zLeBwxy9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9cf7acc1-2d8f-4259-9241-c7a3a27b2a7b"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 7s/step - accuracy: 0.6421 - loss: 0.6461\n",
      "test loss, test acc:  [0.6450586915016174, 0.6477188467979431]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#4) 리뷰 예측해보기"
   ],
   "metadata": {
    "id": "R3AST2zUxokx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  bos_token = [tokenizer.bos_token]\n",
    "  eos_token = [tokenizer.eos_token]\n",
    "  tokens = bos_token + tokenizer.tokenize(new_sentence) + eos_token\n",
    "  input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "  input_id = pad_sequences([input_id], maxlen = max_seq_len, value = tokenizer.pad_token_id, padding = 'post')[0]\n",
    "  input_id = np.array([input_id])\n",
    "  score = model.predict(input_id)[0][0]\n",
    "\n",
    "  if (score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1- score) * 100))"
   ],
   "metadata": {
    "id": "GWNhI2xExkML"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sentiment_predict(\"보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에\")"
   ],
   "metadata": {
    "id": "jv47-3ENyfxn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed4c4cca-a4a8-4f44-bfd1-155a90c4a6ec"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "60.10% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentiment_predict(\"스토리는 확실히 실망이였지만 배우들 연기력이 대박이였다 특히 이제훈 연기 정말 ... 이 배우들로 이렇게밖에 만들지 못한 영화는 아쉽지만 배우들 연기력과 사운드는 정말 빛났던 영화. 기대하고 극장에서 보면 많이 실망했겠지만 평점보고 기대없이 집에서 편하게 보면 괜찮아요. 이제훈님 연기력은 최고인 것 같습니다\")"
   ],
   "metadata": {
    "id": "hbt-h16bykXF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b83c048e-a8f3-4f68-d55b-7322cbb3bb82"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "51.65% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')"
   ],
   "metadata": {
    "id": "khU4FFOjzdtx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f7b3f451-cc76-4d18-d451-b43fe7b21f66"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "68.17% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "hRXfJJmPwJd2"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
